---
title: "working_with_text"
format: html
editor: visual
---

# Text analysis

In this tutorial we are going to start working with the text that we scraped last time. We will take the tidy approach to text analysis because it is fairly intuitive in that it treats text as data frames for analysis.

Furthermore, the text converted into a data frame can be converted to a variety of formats that allow it to be analyzed by other popular ra programs such as quanteda. While the examples are different and we won't cover all of the topics in the book you can find much of this material in [**Text Mining with R**](https://www.tidytextmining.com/index.html "A Tidy Approach")**: A Tidy Approach** listed in the syllabus

## A Corpus

For our analysis we need text.  The raw text is the corpus that we work on.  The corpus that we are interested in varies depending on our researh objectives.  For example, a corpus can contain a newspaper article, multiple articles, tweets about a particular topic or from a group of people. How we put together the relevant corpus depends on the objective of our analysis.  

As an example, here we will use the news-paper article that we scraped.   

"A token is a meaningful unit of text, most often a word, that we are interested in using for further analysis, and tokenization is the process of splitting text into tokens." (TMR)

"The default tokenizing is for words, but other options include characters, n-grams, sentences, lines, paragraphs, or separation around a regex pattern."(TMR)

remove stop words; that are not useful for an analysis, typically extremely common words such as \"the\", \"of\", \"to\", and so forth in English

```{r}
#| echo: false
2 * 2
```
